{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befef0e6",
   "metadata": {},
   "source": [
    "## Pr√©paration du dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f8b0b",
   "metadata": {},
   "source": [
    "### Recup dataset , transforms et datatloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db088ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEG_LABEL_COLS = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "SEG_DIR = '/home/tibia/Projet_Hemorragie/Seg_hemorragie/split_MONAI'\n",
    "CLASSIFICATION_DATA_DIR = '/home/tibia/Projet_Hemorragie/MBH_label_case'\n",
    "SAVE_DIR = \"/home/tibia/Projet_Hemorragie/MBH_multitask_libMTL/saved_models\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "# ======================\n",
    "# DATA PREPARATION\n",
    "# ======================\n",
    "def get_segmentation_data(split=\"train\"):\n",
    "    img_dir = Path(SEG_DIR) / split / \"img\"\n",
    "    seg_dir = Path(SEG_DIR) / split / \"seg\"\n",
    "    \n",
    "    images = sorted(img_dir.glob(\"*.nii.gz\"))\n",
    "    labels = sorted(seg_dir.glob(\"*.nii.gz\"))\n",
    "    \n",
    "    assert len(images) == len(labels), \"Mismatch between image and label counts\"\n",
    "\n",
    "    data = []\n",
    "    for img, lbl in zip(images, labels):\n",
    "        data.append({\n",
    "            \"image\": str(img),\n",
    "            \"label\": str(lbl),\n",
    "        })\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_classification_data(split=\"train\"):\n",
    "    csv_path = Path(CLASSIFICATION_DATA_DIR) / \"splits\" / f\"{split}_split.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    nii_dir = Path(CLASSIFICATION_DATA_DIR)\n",
    "    label_cols = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "    \n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = str(nii_dir / f\"{row['patientID_studyID']}.nii.gz\")\n",
    "        label = np.array([row[col] for col in label_cols], dtype=np.float32)\n",
    "        \n",
    "        data.append({\n",
    "            \"image\": image_path,\n",
    "            \"label\": label\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac712a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#D√©finitions des transformations MONAI\n",
    "from monai import transforms as T\n",
    "import torch\n",
    " \n",
    "def get_segmentation_transform(mode='train'):\n",
    "    # Transforms de base (toujours appliqu√©es)\n",
    "    base_transforms = [\n",
    "        T.LoadImaged(keys=[\"image\", \"label\"], image_only=True ),\n",
    "        T.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        T.CropForegroundd(keys=[\"image\", \"label\"], source_key='image'),\n",
    "        T.Orientationd(keys=[\"image\", \"label\"], axcodes='RAS'),\n",
    "        T.Spacingd(keys=[\"image\", \"label\"], pixdim=(1., 1., 1.), mode=[\"bilinear\", \"nearest\"]),\n",
    "        T.SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(96, 96, 96)),\n",
    "        T.ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-10,\n",
    "            a_max=140,\n",
    "            b_min=0.0, b_max=1.0, clip=True\n",
    "        ),\n",
    "        T.SelectItemsD(keys=[\"image\", \"label\"])\n",
    "        \n",
    "    ]\n",
    "    augmentation_transforms = []\n",
    "    if mode == 'train':\n",
    "        augmentation_transforms = [\n",
    "            T.RandCropByPosNegLabeld(\n",
    "                keys=['image', 'label'],\n",
    "                image_key='image',\n",
    "                label_key='label',\n",
    "                pos=5.0,\n",
    "                neg=1.0,\n",
    "                spatial_size=(96, 96, 96),\n",
    "                num_samples=2\n",
    "            ),\n",
    "            T.RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0, 1], prob=0.5),\n",
    "            T.RandRotate90d(keys=[\"image\", \"label\"], spatial_axes=(0, 1), prob=0.5),\n",
    "            T.RandScaleIntensityd(keys=[\"image\"], factors=0.1, prob=0.5),\n",
    "            T.RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "            \n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # T.RandGaussianNoised(keys=[\"image\"], prob=0.5, mean=0.0, std=0.1),\n",
    "        \n",
    "        # # 3. Optionnel mais top : Flou (simulation de mouvement patient) ou Nettet√©\n",
    "        # T.RandGaussianSmoothd(keys=[\"image\"], sigma_x=(0.5, 1.0), sigma_y=(0.5, 1.0), sigma_z=(0.5, 1.0), prob=0.1),\n",
    "     # √† tester\n",
    "        \n",
    "    final_transform = [T.EnsureTyped(keys=[\"image\", \"label\"], track_meta=False)]\n",
    "    \n",
    "\n",
    "    all_transforms = base_transforms + augmentation_transforms + final_transform\n",
    "    \n",
    "       \n",
    "    \n",
    "    return T.Compose(all_transforms)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_classification_transform(mode='train'):\n",
    "    # Transforms de base (toujours appliqu√©es)\n",
    "    base_transforms = [\n",
    "            T.LoadImaged(keys=[\"image\"], image_only=True),\n",
    "            T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            T.Orientationd(keys=[\"image\"], axcodes='RAS'),\n",
    "            T.Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "            T.CropForegroundd(keys=[\"image\"], source_key='image'),\n",
    "            T.ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-10,a_max=140, \n",
    "                b_min=0.0, b_max=1.0, \n",
    "                clip=True) ,\n",
    "            T.RandSpatialCropd(keys=[\"image\"], roi_size=(96, 96, 96), random_size=False)]\n",
    "        \n",
    "    augmentation_transforms = []      \n",
    "    if mode == 'train':\n",
    "        augmentation_transforms = [\n",
    "            T.RandFlipd(keys=[\"image\"], spatial_axis=[0, 1, 2], prob=0.5),\n",
    "            T.RandRotate90d(keys=[\"image\"], spatial_axes=(0, 1), prob=0.5),\n",
    "            T.RandScaleIntensityd(keys=[\"image\"], factors=0.1, prob=0.5),\n",
    "            T.RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "            \n",
    "        ]\n",
    "        \n",
    "    final_transform = [T.ToTensord(keys=[\"image\", \"label\"]),\n",
    "                       T.SelectItemsD(keys=[\"image\", \"label\"]),\n",
    "                       T.EnsureTyped(keys=[\"image\", \"label\"], track_meta=False)]\n",
    "        \n",
    "    all_transforms = base_transforms + augmentation_transforms + final_transform\n",
    "        \n",
    "    return T.Compose(all_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d36e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "from monai.data import DataLoader, PersistentDataset\n",
    "seg_train_data=get_segmentation_data(\"train\")\n",
    "cls_train_data=get_classification_data(\"train\")\n",
    "\n",
    "seg_train_dataset = PersistentDataset(\n",
    "        seg_train_data, \n",
    "        transform=get_segmentation_transform('train'),\n",
    "        cache_dir=os.path.join(SAVE_DIR, \"cache_train\")\n",
    "    )\n",
    "\n",
    "cls_train_dataset = PersistentDataset(\n",
    "        cls_train_data,\n",
    "        transform=get_classification_transform('train'),\n",
    "        cache_dir=os.path.join(SAVE_DIR, \"cache_train\"))\n",
    "    \n",
    "#Val dataset\n",
    "seg_val_data=get_segmentation_data(\"val\")\n",
    "cls_val_data=get_classification_data(\"val\")\n",
    "seg_val_dataset = PersistentDataset(\n",
    "        seg_val_data, \n",
    "        transform=get_segmentation_transform('val'),    \n",
    "        cache_dir=os.path.join(SAVE_DIR, \"cache_val\")\n",
    "    )   \n",
    "cls_val_dataset = PersistentDataset(\n",
    "        cls_val_data,\n",
    "        transform=get_classification_transform('val'),\n",
    "        cache_dir=os.path.join(SAVE_DIR, \"cache_val\"))      \n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "seg_train_loader = DataLoader(\n",
    "        seg_train_dataset, \n",
    "        batch_size=2, \n",
    "        shuffle=True, \n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    ")\n",
    "\n",
    "cls_train_loader = DataLoader(\n",
    "        cls_train_dataset, \n",
    "        batch_size=2, \n",
    "        shuffle=True, \n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    ")\n",
    "  \n",
    "train_dataloaders = {'segmentation': seg_train_loader,\n",
    "                     'classification': cls_train_loader\n",
    "                     }\n",
    "\n",
    "\n",
    "seg_val_loader = DataLoader(\n",
    "        seg_val_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=False, \n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    ")   \n",
    "\n",
    "cls_val_loader = DataLoader(  \n",
    "        cls_val_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=False, \n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    ")\n",
    "val_dataloaders = {'segmentation': seg_val_loader,\n",
    "                   'classification': cls_val_loader\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9aca02",
   "metadata": {},
   "source": [
    "### Tests de shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a329e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- AVANT EnsureTyped ---------------\n",
      "Dans LoadImaged, les donn√©es sont initialement numpy arrays.\n",
      "--------------- APR√àS EnsureTyped ----------------\n",
      "Type image : <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "Type label : <class 'monai.data.meta_tensor.MetaTensor'>\n",
      "\n",
      "Est-ce que c'est un torch.Tensor ?  True\n",
      "Est-ce un MetaTensor MONAI ?         MetaTensor\n",
      "\n",
      "--- Metadata de l'image ---\n",
      "{'intent_p1': tensor([0.]), 'qoffset_x': tensor([125.]), 'cal_min': tensor([0.]), original_affine: tensor([[[-4.8828e-01,  0.0000e+00,  0.0000e+00,  1.2500e+02],\n",
      "         [ 0.0000e+00, -4.6168e-01, -1.7216e+00,  1.6214e+02],\n",
      "         [ 0.0000e+00, -1.5897e-01,  4.9999e+00,  2.5580e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
      "       dtype=torch.float64), 'as_closest_canonical': tensor([False]), 'session_error': tensor([0], dtype=torch.int16), 'datatype': tensor([8], dtype=torch.int16), 'quatern_d': tensor([0.9863]), 'filename_or_obj': ['/home/tibia/Projet_Hemorragie/Seg_hemorragie/split_MONAI/train/img/ID_0237f3c9_ID_40015688b9.nii.gz'], 'pixdim': tensor([[1.0000, 0.4883, 0.4883, 5.2880, 0.0000, 0.0000, 0.0000, 0.0000]]), 'qform_code': tensor([1], dtype=torch.int16), 'toffset': tensor([0.]), 'srow_x': tensor([[0., 0., 0., 0.]]), 'qoffset_y': tensor([162.1419]), original_channel_dim: tensor([nan], dtype=torch.float64), 'bitpix': tensor([32], dtype=torch.int16), 'slice_duration': tensor([0.]), spatial_shape: tensor([[512, 512,  27]], dtype=torch.int16), 'sizeof_hdr': tensor([348], dtype=torch.int32), 'srow_y': tensor([[0., 0., 0., 0.]]), 'quatern_c': tensor([-0.1650]), 'dim': tensor([[  3, 512, 512,  27,   1,   1,   1,   1]], dtype=torch.int16), 'glmax': tensor([0], dtype=torch.int32), 'vox_offset': tensor([0.]), 'scl_slope': tensor([nan]), 'glmin': tensor([0], dtype=torch.int32), 'qoffset_z': tensor([25.5799]), 'sform_code': tensor([0], dtype=torch.int16), affine: tensor([[[-4.8828e-01,  0.0000e+00,  0.0000e+00,  1.2500e+02],\n",
      "         [ 0.0000e+00, -4.6168e-01, -1.7216e+00,  1.6214e+02],\n",
      "         [ 0.0000e+00, -1.5897e-01,  4.9999e+00,  2.5580e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
      "       dtype=torch.float64), space: [RAS], 'slice_start': tensor([0], dtype=torch.int16), 'extents': tensor([0], dtype=torch.int32), 'dim_info': tensor([0], dtype=torch.uint8), 'srow_z': tensor([[0., 0., 0., 0.]]), 'intent_p3': tensor([0.]), 'intent_p2': tensor([0.]), 'slice_code': tensor([0], dtype=torch.uint8), 'cal_max': tensor([0.]), 'intent_code': tensor([0], dtype=torch.int16), 'scl_inter': tensor([nan]), 'quatern_b': tensor([0.]), 'xyzt_units': tensor([2], dtype=torch.uint8), 'slice_end': tensor([0], dtype=torch.int16)}\n",
      "\n",
      "--- Metadata du label ---\n",
      "{'intent_p1': tensor([0.]), 'qoffset_x': tensor([125.]), 'cal_min': tensor([0.]), original_affine: tensor([[[-4.8828e-01,  0.0000e+00,  0.0000e+00,  1.2500e+02],\n",
      "         [ 0.0000e+00, -4.6168e-01, -1.7216e+00,  1.6214e+02],\n",
      "         [ 0.0000e+00, -1.5897e-01,  4.9999e+00,  2.5580e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
      "       dtype=torch.float64), 'as_closest_canonical': tensor([False]), 'session_error': tensor([0], dtype=torch.int16), 'datatype': tensor([2], dtype=torch.int16), 'quatern_d': tensor([0.9863]), 'filename_or_obj': ['/home/tibia/Projet_Hemorragie/Seg_hemorragie/split_MONAI/train/seg/ID_0237f3c9_ID_40015688b9.nii.gz'], 'pixdim': tensor([[1.0000, 0.4883, 0.4883, 5.2880, 0.0000, 0.0000, 0.0000, 0.0000]]), 'qform_code': tensor([1], dtype=torch.int16), 'toffset': tensor([0.]), 'srow_x': tensor([[ -0.4883,   0.0000,   0.0000, 125.0000]]), 'qoffset_y': tensor([162.1419]), original_channel_dim: tensor([nan], dtype=torch.float64), 'bitpix': tensor([8], dtype=torch.int16), 'slice_duration': tensor([0.]), spatial_shape: tensor([[512, 512,  27]], dtype=torch.int16), 'sizeof_hdr': tensor([348], dtype=torch.int32), 'srow_y': tensor([[  0.0000,  -0.4617,  -1.7216, 162.1419]]), 'quatern_c': tensor([-0.1650]), 'dim': tensor([[  3, 512, 512,  27,   1,   1,   1,   1]], dtype=torch.int16), 'glmax': tensor([0], dtype=torch.int32), 'vox_offset': tensor([0.]), 'scl_slope': tensor([nan]), 'glmin': tensor([0], dtype=torch.int32), 'qoffset_z': tensor([25.5799]), 'sform_code': tensor([1], dtype=torch.int16), affine: tensor([[[-4.8828e-01,  0.0000e+00,  0.0000e+00,  1.2500e+02],\n",
      "         [ 0.0000e+00, -4.6168e-01, -1.7216e+00,  1.6214e+02],\n",
      "         [ 0.0000e+00, -1.5897e-01,  4.9999e+00,  2.5580e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
      "       dtype=torch.float64), space: [RAS], 'slice_start': tensor([0], dtype=torch.int16), 'extents': tensor([0], dtype=torch.int32), 'dim_info': tensor([0], dtype=torch.uint8), 'srow_z': tensor([[ 0.0000, -0.1590,  4.9999, 25.5799]]), 'intent_p3': tensor([0.]), 'intent_p2': tensor([0.]), 'slice_code': tensor([0], dtype=torch.uint8), 'cal_max': tensor([0.]), 'intent_code': tensor([0], dtype=torch.int16), 'scl_inter': tensor([nan]), 'quatern_b': tensor([0.]), 'xyzt_units': tensor([10], dtype=torch.uint8), 'slice_end': tensor([0], dtype=torch.int16)}\n",
      "\n",
      "Shape du tenseur : torch.Size([1, 512, 512, 27])\n",
      "Dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import LoadImaged, EnsureTyped, Compose\n",
    "from monai.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "sample_data = get_segmentation_data(split=\"train\")[:1]  # Prendre un seul √©chantillon pour la d√©monstration\n",
    "# ----------------------------------------------------\n",
    "# Pipeline simple pour d√©monstration\n",
    "# ----------------------------------------------------\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),   # Charge en numpy\n",
    "    # üëâ Avant EnsureTyped : ce sont des numpy arrays\n",
    "   # EnsureTyped(keys=[\"image\", \"label\"])   # Convertit en MetaTensor\n",
    "])\n",
    "\n",
    "dataset = Dataset(data=sample_data, transform=transforms)\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# R√©cup√©ration d'un batch\n",
    "# ----------------------------------------------------\n",
    "batch = next(iter(loader))\n",
    "\n",
    "img = batch[\"image\"]\n",
    "lbl = batch[\"label\"]\n",
    "\n",
    "print(\"--------------- AVANT EnsureTyped ---------------\")\n",
    "print(\"Dans LoadImaged, les donn√©es sont initialement numpy arrays.\")\n",
    "\n",
    "print(\"--------------- APR√àS EnsureTyped ----------------\")\n",
    "print(\"Type image :\", type(img))\n",
    "print(\"Type label :\", type(lbl))\n",
    "\n",
    "print(\"\\nEst-ce que c'est un torch.Tensor ? \", isinstance(img, torch.Tensor))\n",
    "print(\"Est-ce un MetaTensor MONAI ?        \", img.__class__.__name__)\n",
    "\n",
    "# Afficher les m√©tadonn√©es disponibles\n",
    "print(\"\\n--- Metadata de l'image ---\")\n",
    "print(img.meta)\n",
    "\n",
    "print(\"\\n--- Metadata du label ---\")\n",
    "print(lbl.meta)\n",
    "\n",
    "print(\"\\nShape du tenseur :\", img.shape)\n",
    "print(\"Dtype :\", img.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b8a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 96, 96, 96])\n",
      "torch.Size([2, 1, 96, 96, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# shape de ce qui rentre dans le mod√®le\n",
    "for batch in train_dataloaders['segmentation']:\n",
    "    print(batch['image'].shape)\n",
    "    break   \n",
    "\n",
    "for batch in train_dataloaders['classification']:\n",
    "    print(batch['image'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "646b511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEGMENTATION TRAIN BATCH ===\n",
      "Keys: dict_keys(['image', 'label'])\n",
      "Image type: <class 'torch.Tensor'>\n",
      "Label type: <class 'torch.Tensor'>\n",
      "Image shape: torch.Size([4, 1, 96, 96, 96])\n",
      "Label shape: torch.Size([4, 1, 96, 96, 96])\n",
      "\n",
      "=== CLASSIFICATION TRAIN BATCH ===\n",
      "Keys: dict_keys(['image', 'label'])\n",
      "Image type: <class 'torch.Tensor'>\n",
      "Label type: <class 'torch.Tensor'>\n",
      "Label: tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'meta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Attention: classification labels are numpy ‚Üí convert?\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage meta:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'meta'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SEGMENTATION TRAIN BATCH ===\")\n",
    "for batch in seg_train_loader:\n",
    "    print(\"Keys:\", batch.keys())\n",
    "    print(\"Image type:\", type(batch[\"image\"]))\n",
    "    print(\"Label type:\", type(batch[\"label\"]))\n",
    "\n",
    "    # MONAI MetaTensor metadata\n",
    "    #print(\"Image meta:\", batch[\"image\"].meta)\n",
    "    #print(\"Label meta:\", batch[\"label\"].meta)\n",
    "\n",
    "    # shapes\n",
    "    print(\"Image shape:\", batch[\"image\"].shape)\n",
    "    print(\"Label shape:\", batch[\"label\"].shape)\n",
    "\n",
    "    break  # Only inspect first batch\n",
    "\n",
    "print(\"\\n=== CLASSIFICATION TRAIN BATCH ===\")\n",
    "for batch in cls_train_loader:\n",
    "    print(\"Keys:\", batch.keys())\n",
    "    print(\"Image type:\", type(batch[\"image\"]))\n",
    "    print(\"Label type:\", type(batch[\"label\"]))\n",
    "\n",
    "    # Attention: classification labels are numpy ‚Üí convert?\n",
    "    print(\"Label:\", batch[\"label\"])\n",
    "    print(\"Image meta:\", batch[\"image\"].meta)\n",
    "\n",
    "    print(\"Image shape:\", batch[\"image\"].shape)\n",
    "    print(\"Label shape:\", batch[\"label\"].shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086765bc",
   "metadata": {},
   "source": [
    "## Pr√©paration dictionnaire de t√¢che "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4908e4",
   "metadata": {},
   "source": [
    "### Pr√©paration m√©triques et loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21563a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /store/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /store/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "# Losses\n",
    "# Ponderer ensuite pa classe avec WeightSampler\n",
    "\n",
    "from LibMTL.loss import AbsLoss\n",
    "import torch\n",
    "from monai.losses import DiceCELoss\n",
    "\n",
    "class ClassificationLossWrapper(AbsLoss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def compute_loss(self, pred, gt):\n",
    "        return self.loss_fn(pred, gt.float())\n",
    "    \n",
    "class SegmentationLossWrapper(AbsLoss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_fn = DiceCELoss(\n",
    "            include_background=False,\n",
    "            to_onehot_y=True,\n",
    "            softmax=True\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, pred, gt):\n",
    "        return self.loss_fn(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe198a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LibMTL.metrics import AbsMetric\n",
    "import torch\n",
    "\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "\n",
    "class MultiLabelAUCMetric(AbsMetric):\n",
    "    def __init__(self, num_labels=6):\n",
    "        super().__init__()\n",
    "        self.metric = MultilabelAUROC(num_labels=num_labels, average=None)   # par classe\n",
    "        self.metric_mean = MultilabelAUROC(num_labels=num_labels, average=\"macro\")  # moyenne\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def update_fun(self, pred, gt):\n",
    "        # pred = logits -> transform needed\n",
    "        pred = torch.sigmoid(pred)\n",
    "        gt=gt.detach().cpu().long() #  pour torchmetrics veut des long\n",
    "        pred=pred.detach().cpu()\n",
    "        \n",
    "        self.metric.update(pred,gt)\n",
    "        self.metric_mean.update(pred,gt)\n",
    "\n",
    "    def score_fun(self):\n",
    "        per_class = self.metric.compute().tolist()\n",
    "        mean_auc = self.metric_mean.compute().item()\n",
    "        return per_class + [mean_auc]\n",
    "\n",
    "    def reinit(self):\n",
    "        super().reinit()\n",
    "        self.metric.reset()\n",
    "        self.metric_mean.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "from LibMTL.metrics import AbsMetric\n",
    "from monai.metrics import DiceMetric,DiceHelper\n",
    "from monai.utils import MetricReduction, deprecated_arg\n",
    "        \n",
    "class DiceMetricAdapter(AbsMetric):\n",
    "    \"\"\"\n",
    "    Cet adaptateur impl√©mente AbsMetric pour calculer le Dice Score correctement.\n",
    "    \n",
    "    - `update_fun` utilise DiceHelper pour obtenir les scores bruts (B, C) \n",
    "      et les stocke dans `self.record`.\n",
    "    - `score_fun` agr√®ge tous les scores de `self.record` et calcule \n",
    "      la moyenne finale (le \"score des totaux\" √©mul√©).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, include_background=False):\n",
    "        # Initialise self.record et self.bs\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.include_background = include_background\n",
    "        \n",
    "        # On utilise DiceHelper comme \"calculateur\" ponctuel.\n",
    "        # On lui demande de NE PAS faire de r√©duction (reduction=\"none\")\n",
    "        # car on veut stocker les scores bruts (Batch, Classes).\n",
    "        self.dice_helper = DiceHelper(\n",
    "            include_background=include_background,\n",
    "            num_classes=num_classes,\n",
    "            reduction=MetricReduction.NONE,\n",
    "            ignore_empty=True,  # Important : ignore les cas o√π le GT est vide\n",
    "            apply_argmax=False  # On le fera nous-m√™mes dans update_fun\n",
    "        )\n",
    "\n",
    "    def update_fun(self, pred, gt):\n",
    "        \"\"\"\n",
    "        Appel√© √† chaque batch. Calcule les scores (B, C) et les stocke.\n",
    "        \n",
    "        Args:\n",
    "            pred (torch.Tensor): Pr√©dictions (logits) de forme (B, C, H, W, D)\n",
    "            gt (torch.Tensor): V√©rit√© terrain (labels) de forme (B, 1, H, W, D)\n",
    "        \"\"\"\n",
    "        # 1. Convertir les logits en labels\n",
    "        # DiceHelper attend des labels, pas des logits\n",
    "        pred_labels = torch.argmax(pred, dim=1, keepdim=True)\n",
    "        \n",
    "        # 2. Calculer les scores Dice pour ce batch\n",
    "        # Le r√©sultat est un tenseur de (B, num_classes_calcul√©es)\n",
    "        # ex: (B, 5) si num_classes=6 et include_background=False\n",
    "        batch_dice_scores,_ = self.dice_helper(pred_labels, gt)\n",
    "        \n",
    "        # 3. Stocker ce tenseur dans notre \"record\"\n",
    "        self.record.append(batch_dice_scores)\n",
    "        \n",
    "        # 4. Stocker la taille du batch (comme le fait AbsMetric)\n",
    "        self.bs.append(pred.shape[0])\n",
    "\n",
    "    def score_fun(self):\n",
    "        \"\"\"\n",
    "        Appel√© √† la fin de l'√©poque. Agr√®ge les scores et calcule la moyenne. Peut etre √† modifier pour le loggage de chaque dice\n",
    "        \"\"\"\n",
    "        if not self.record:\n",
    "            # Retourne un score pour chaque classe, mis √† 0\n",
    "            num_expected_classes = self.num_classes - (1 if not self.include_background else 0)\n",
    "            return torch.zeros(num_expected_classes)\n",
    "            \n",
    "        # 1. Rassembler tous les tenseurs de (B, C) en un seul\n",
    "        # grand tenseur de (Total_B, C)\n",
    "        all_scores = torch.cat(self.record, dim=0)\n",
    "        \n",
    "        # 2. Calculer la moyenne sur la dimension des batches (dim=0)\n",
    "        # On utilise nanmean pour ignorer les NaN (cas des GT vides)\n",
    "        # C'est la fa√ßon correcte d'agr√©ger le Dice.\n",
    "        mean_scores_per_class = torch.nanmean(all_scores, dim=0)\n",
    "        #mean_gloabal = torch.nanmean(mean_scores_per_class)\n",
    "        \n",
    "        # `score_fun` est cens√© retourner une \"liste\", mais un tenseur\n",
    "        # est plus utile. On retourne la moyenne par classe.\n",
    "        return mean_scores_per_class.tolist()\n",
    "    \n",
    "    # La m√©thode reinit() est h√©rit√©e de AbsMetric et fonctionne parfaitement\n",
    "    # car elle vide self.record et self.bs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e32842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_pred shape : torch.Size([2, 6, 96, 96, 96])\n",
      "dummy_label shape : torch.Size([2, 1, 96, 96, 96])\n",
      "batch_dice_scores shape : torch.Size([2, 5])\n",
      "record :  [tensor([[0.1662, 0.1655, 0.1659, 0.1675, 0.1670],\n",
      "        [0.1674, 0.1660, 0.1658, 0.1665, 0.1658]])]\n",
      "record after 2 batches:  [tensor([[0.1662, 0.1655, 0.1659, 0.1675, 0.1670],\n",
      "        [0.1674, 0.1660, 0.1658, 0.1665, 0.1658]]), tensor([[0.1662, 0.1659, 0.1672, 0.1662, 0.1659],\n",
      "        [0.1674, 0.1669, 0.1682, 0.1666, 0.1684]])]\n",
      "all_scores shape after cat:  torch.Size([4, 5])\n",
      "mean_scores_per_class:  tensor([0.1668, 0.1661, 0.1668, 0.1667, 0.1668])\n"
     ]
    }
   ],
   "source": [
    "## test torch.cat\n",
    "record = []\n",
    "dummy_pred = torch.randn(2, 6, 96, 96, 96)\n",
    "dummy_label =torch.argmax(dummy_pred,dim=1,keepdim=True)\n",
    "dummy_gt = torch.randint(low=0, high=6, size=(2, 1, 96, 96, 96)) # 6 classes (0, 1, 2, 3, 4, 5)\n",
    "print(\"dummy_pred shape :\", dummy_pred.shape)\n",
    "print(\"dummy_label shape :\", dummy_label.shape)\n",
    "batch_dice_scores, _ = DiceHelper(\n",
    "    include_background=False,\n",
    "    num_classes=6,\n",
    "    reduction=MetricReduction.NONE,\n",
    "    ignore_empty=True,\n",
    "    apply_argmax=False\n",
    ")(dummy_label, dummy_gt)\n",
    "print(\"batch_dice_scores shape :\", batch_dice_scores.shape)\n",
    "\n",
    "record.append(batch_dice_scores)\n",
    "print(\"record : \", record)\n",
    "\n",
    "\n",
    "## nouveau batch :\n",
    "dummy_pred2 = torch.randn(2, 6, 96, 96, 96)\n",
    "dummy_label2 =torch.argmax(dummy_pred2,dim=1,keepdim=True)\n",
    "dummy_gt2 = torch.randint(low=0, high=6, size=(2, 1, 96, 96, 96)) # 6 classes (0, 1, 2, 3, 4, 5)\n",
    "batch_dice_scores2, _ = DiceHelper(\n",
    "    include_background=False,\n",
    "    num_classes=6,\n",
    "    reduction=MetricReduction.NONE,\n",
    "    ignore_empty=True,\n",
    "    apply_argmax=False\n",
    ")(dummy_label2, dummy_gt2)\n",
    "record.append(batch_dice_scores2)\n",
    "\n",
    "print(\"record after 2 batches: \", record)\n",
    "all_scores = torch.cat(record, dim=0)\n",
    "print(\"all_scores shape after cat: \", all_scores.shape)\n",
    "mean_scores_per_class = torch.nanmean(all_scores, dim=0)\n",
    "print(\"mean_scores_per_class: \", mean_scores_per_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aedc81",
   "metadata": {},
   "source": [
    "### Dictionnaire de t√¢ches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98176c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des m√©triques de classification : ['AUC_any', 'AUC_epidural', 'AUC_intraparenchymal', 'AUC_intraventricular', 'AUC_subarachnoid', 'AUC_subdural', 'AUC_Mean']\n",
      "Noms des m√©triques de segmentation   : ['Dice_any', 'Dice_epidural', 'Dice_intraparenchymal', 'Dice_intraventricular', 'Dice_subarachnoid', 'Dice_subdural']\n",
      "Nombre de t√¢ches d√©finies : 2\n"
     ]
    }
   ],
   "source": [
    "class_names = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "seg_metric_names_list= [ 'EDH', ]\n",
    "metric_names_list = [f\"AUC_{name}\" for name in class_names] + [\"AUC_Mean\"]\n",
    "seg_metric_names_list = [f\"Dice_{name}\" for name in class_names]\n",
    "\n",
    "print(\"Noms des m√©triques de classification :\", metric_names_list)\n",
    "print(\"Noms des m√©triques de segmentation   :\", seg_metric_names_list)\n",
    "# dictionnaire de t√¢ches\n",
    "\n",
    "task_dict = {\n",
    "    'classification': {\n",
    "        'loss_fn': ClassificationLossWrapper(),\n",
    "        'metrics_fn': MultiLabelAUCMetric(num_labels=6),\n",
    "        'metrics': ['val_auc_class_0', 'val_auc_class_1', 'val_auc_class_2', \n",
    "                   'val_auc_class_3', 'val_auc_class_4', 'val_auc_class_5', \n",
    "                   'val_auc_mean'],\n",
    "        'weight': [1.0]\n",
    "    },\n",
    "    'segmentation': {\n",
    "        'loss_fn': SegmentationLossWrapper(),\n",
    "        'metrics_fn': DiceMetricAdapter(num_classes=6, include_background=False),\n",
    "        'metrics': ['dice_c1', 'dice_c2', 'dice_c3', 'dice_c4', 'dice_c5'],\n",
    "        'weight': [1.0] * 5\n",
    "    }\n",
    "}\n",
    "# self.task_num = len(task_dict)\n",
    "task_num = len(task_dict)\n",
    "print(f\"Nombre de t√¢ches d√©finies : {task_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa932a",
   "metadata": {},
   "source": [
    "### Petits tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0f10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from monai.networks import nets as monai_nets\n",
    "\n",
    "model = monai_nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=6,\n",
    "    channels=(32, 64, 128, 256, 320, 320),\n",
    "    strides=(2, 2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f163b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels Shape: torch.Size([2, 1, 32, 32, 16])\n",
      "Predicted Labels after Softmax Shape: torch.Size([2, 6, 32, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "B = 2    # Batch Size (nombre d'√©chantillons)\n",
    "C = 6    # Nombre de Classes (+ background)\n",
    "H = 32   # Hauteur (Height)\n",
    "W = 32   # Largeur (Width)\n",
    "D = 16   # Profondeur (Depth)\n",
    "\n",
    "\n",
    "pred = torch.rand(B, C, H, W, D) \n",
    "pred_labels = torch.argmax(pred, dim=1, keepdim=True)\n",
    "pred_lables_2= torch.nn.Softmax(dim=1)(pred)\n",
    "\n",
    "print(\"Predicted Labels Shape:\", pred_labels.shape)  # Devrait afficher (2, 1, 32, 32, 16)\n",
    "print(\"Predicted Labels after Softmax Shape:\", pred_lables_2.shape)  # Devrait afficher (2, 6, 32, 32, 16)\n",
    "# --- Tenseur de V√©rit√© Terrain (Labels) ---\n",
    "# Forme d√©sir√©e : (B, 1, H, W, D) -> (2, 1, 32, 32, 16)\n",
    "# Utilisation de torch.randint pour simuler des labels (entiers de 0 √† C-1)\n",
    "# Les labels doivent √™tre des entiers et non des flottants.\n",
    "gt = torch.randint(low=0, high=C, size=(B, 1, H, W, D))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0029247",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee196abb",
   "metadata": {},
   "source": [
    "### Encodeur / D√©codeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7545bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilis√© : cuda\n",
      "Features 4:  256\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets.basic_unet import TwoConv, Down, UpCat\n",
    "\n",
    "\n",
    "class HemorrhageEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Cette classe contient la partie descendante (encodeur) du U-Net.\n",
    "    Elle est partag√©e par les deux t√¢ches.\n",
    "    Son forward pass retourne une liste de toutes les feature maps\n",
    "    n√©cessaires pour les skip connections du d√©codeur de segmentation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int = 3,\n",
    "        in_channels: int = 1,\n",
    "        features: Sequence[int] = (32, 32, 64, 128, 256, 32),\n",
    "        act: str | tuple = (\"LeakyReLU\", {\"negative_slope\": 0.1, \"inplace\": True}),\n",
    "        norm: str | tuple = (\"instance\", {\"affine\": True}),\n",
    "        bias: bool = True,\n",
    "        dropout: float | tuple = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Assure que 'features' a la bonne longueur\n",
    "        self.fea = nn.Parameter(torch.tensor(features), requires_grad=False)\n",
    "        \n",
    "        self.conv_0 = TwoConv(spatial_dims, in_channels, self.fea[0], act, norm, bias, dropout)\n",
    "        self.down_1 = Down(spatial_dims, self.fea[0], self.fea[1], act, norm, bias, dropout)\n",
    "        self.down_2 = Down(spatial_dims, self.fea[1], self.fea[2], act, norm, bias, dropout)\n",
    "        self.down_3 = Down(spatial_dims, self.fea[2], self.fea[3], act, norm, bias, dropout)\n",
    "        self.down_4 = Down(spatial_dims, self.fea[3], self.fea[4], act, norm, bias, dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> list[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Le forward pass de l'encodeur.\n",
    "        Retourne une liste contenant le bottleneck (x4) et toutes les\n",
    "        sorties interm√©diaires pour les skip connections.\n",
    "        \"\"\"\n",
    "        x0 = self.conv_0(x)\n",
    "        x1 = self.down_1(x0)\n",
    "        x2 = self.down_2(x1)\n",
    "        x3 = self.down_3(x2)\n",
    "        x4 = self.down_4(x3)  # C'est le bottleneck (la repr√©sentation partag√©e)\n",
    "        \n",
    "        return [x4, x3, x2, x1, x0]\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# 2. LES D√âCODEURS (Les t√™tes sp√©cifiques √† chaque t√¢che)\n",
    "# ========================================================================\n",
    "\n",
    "class SegmentationDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Le d√©codeur pour la t√¢che de segmentation.\n",
    "    Il prend la liste de features de l'encodeur et reconstruit le masque.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int = 3,\n",
    "        out_channels: int = 6,\n",
    "        features: Sequence[int] = (32, 32, 64, 128, 256, 32),\n",
    "        act: str | tuple = (\"LeakyReLU\", {\"negative_slope\": 0.1, \"inplace\": True}),\n",
    "        norm: str | tuple = (\"instance\", {\"affine\": True}),\n",
    "        bias: bool = True,\n",
    "        dropout: float | tuple = 0.0,\n",
    "        upsample: str = \"deconv\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        fea = nn.Parameter(torch.tensor(features), requires_grad=False)\n",
    "        \n",
    "        self.upcat_4 = UpCat(spatial_dims, fea[4], fea[3], fea[3], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_3 = UpCat(spatial_dims, fea[3], fea[2], fea[2], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_2 = UpCat(spatial_dims, fea[2], fea[1], fea[1], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_1 = UpCat(spatial_dims, fea[1], fea[0], fea[5], act, norm, bias, dropout, upsample, halves=False)\n",
    "        self.final_conv = nn.Conv3d(fea[5], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, enc_out: list[torch.Tensor]) -> torch.Tensor:\n",
    "        # On r√©cup√®re les tenseurs de la liste fournie par l'encodeur\n",
    "        x4, x3, x2, x1, x0 = enc_out\n",
    "        \n",
    "        u4 = self.upcat_4(x4, x3)\n",
    "        u3 = self.upcat_3(u4, x2)\n",
    "        u2 = self.upcat_2(u3, x1)\n",
    "        u1 = self.upcat_1(u2, x0)\n",
    "        \n",
    "        return self.final_conv(u1)\n",
    "\n",
    "class ClassificationDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Le d√©codeur pour la t√¢che de classification.\n",
    "    Il prend la liste de features de l'encodeur mais n'utilise que le\n",
    "    bottleneck (x4) pour pr√©dire les classes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,  # Doit correspondre √† features[4] de l'encodeur\n",
    "        num_cls_classes: int = 6,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # T√™te de classification, exactement comme avant\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((4, 4, 4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features * 4 * 4 * 4, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_cls_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, enc_out: list[torch.Tensor]) -> torch.Tensor:\n",
    "        # On ne prend que le bottleneck (le premier √©l√©ment de la liste)\n",
    "        x4 = enc_out[0]\n",
    "        \n",
    "        # Toute la logique d'agr√©gation de patches a disparu !\n",
    "        # On passe directement les features √† la t√™te de classification.\n",
    "        return self.cls_head(x4)\n",
    "\n",
    "# ========================================================================\n",
    "# 3. ASSEMBLAGE FINAL POUR LibMTL\n",
    "# ========================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device utilis√© : {device}\")\n",
    "# D√©finis tes param√®tres\n",
    "task_name = [\"segmentation\", \"classification\"]\n",
    "features = (32, 32, 64, 128, 256, 32)\n",
    "print(\"Features 4: \", features[4])\n",
    "\n",
    "# Cr√©e une instance de l'encodeur partag√©\n",
    "encoder = HemorrhageEncoder(features=features).to(device)\n",
    "\n",
    "# Cr√©e un dictionnaire de d√©codeurs\n",
    "decoders = nn.ModuleDict({\n",
    "    'segmentation': SegmentationDecoder(\n",
    "        out_channels=6, # 6 classes de segmentation\n",
    "        features=features\n",
    "    ).to(device),\n",
    "    'classification': ClassificationDecoder(\n",
    "        in_features=features[4], # La taille du bottleneck (256)\n",
    "        num_cls_classes=6 # 6 classes de classification\n",
    "    ).to(device)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401e971",
   "metadata": {},
   "source": [
    "### Param√®tres ( optimiseur ,scheduler , kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ab0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres optim & scheduler\n",
    "optim_param = {\n",
    "    'optim': 'sgd', \n",
    "    'lr': 1e-3, \n",
    "    'weight_decay': 3e-5,  # 0.00003 est √©gal √† 3e-5\n",
    "    'momentum': 0.99, \n",
    "    'nesterov': True\n",
    "}\n",
    "\n",
    "lengths = [len(loader) for loader in train_dataloaders.values()]\n",
    "\n",
    "# 2. Trouver le dataloader le plus long (c'est sur lui que LibMTL se cale)\n",
    "steps_per_epoch = max(lengths)\n",
    "\n",
    "\n",
    "total_steps = steps_per_epoch * 1000  # 1000 epochs \n",
    "\n",
    "scheduler_param = {\n",
    "    'scheduler': 'linearschedulewithwarmup',  # Correspond √† get_linear_schedule_with_warmup\n",
    "    'num_warmup_steps': 0, \n",
    "    'num_training_steps': total_steps\n",
    "   }\n",
    "# --- 2. D√âFINITION MANUELLE DE KWARGS  ---\n",
    "\n",
    "# Arguments sp√©cifiques √† l'architecture (Exemple pour un U-Net 3D ou une archi complexe)\n",
    "arch_args = {\n",
    "    \n",
    "    # Si vous utilisez CGC, PLE, ou MMoE, vous devez sp√©cifier la taille d'image et le nombre d'experts\n",
    "    # 'img_size': (96, 96, 96), \n",
    "    # 'num_experts': [4, 4, 4], \n",
    "    \n",
    "    # Si votre encodeur ResNet a des arguments sp√©cifiques, mettez-les ici\n",
    "    # Ex: 'channels': 3 # Si vous devez le passer √† l'initialisation de l'encodeur\n",
    "}\n",
    "\n",
    "# Arguments sp√©cifiques √† la m√©thode de pond√©ration (Exemple pour 'EW' qui n'a besoin de rien)\n",
    "weight_args = {\n",
    "    # Pour EW (Equal Weighting), c'est souvent vide.\n",
    "}\n",
    "\n",
    "# Si vous utilisiez DWA, vous d√©finiriez T :\n",
    "# weight_args = {'T': 1.0} \n",
    "\n",
    "# Si vous utilisiez GradNorm, vous d√©finiriez alpha :\n",
    "# weight_args = {'alpha': 0.1}\n",
    "\n",
    "# --- 3. CONSOLIDER KWARGS (Optionnel mais propre) ---\n",
    "\n",
    "# Cr√©e le dictionnaire kwargs global\n",
    "kwargs = {\n",
    "    'arch_args': arch_args,\n",
    "    'weight_args': weight_args\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d42bd7",
   "metadata": {},
   "source": [
    "### Petits tests ( shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46fa0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilis√© : cuda\n",
      "torch.Size([2, 256, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device utilis√© : {device}\")\n",
    "tensor_test = torch.rand(2, 1, 96, 96, 96).to(device)  # Batch de 2 √©chantillons\n",
    "encoder_outputs = encoder(tensor_test)\n",
    "print (encoder_outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aad56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs = encoder(tensor_test)\n",
    "classification_output = decoders['classification'](encoder_outputs)\n",
    "print (classification_output.shape)\n",
    "\n",
    "segmentation_output = decoders['segmentation'](encoder_outputs)\n",
    "print (segmentation_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f224b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé INSPECTION : Train Segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üì¶ C'est un DICTIONNAIRE unique.\n",
      "      - Cl√© 'image' : <class 'torch.Tensor'>\n",
      "      - Cl√© 'label' : <class 'torch.Tensor'>\n",
      "\n",
      "--- INSPECTION DES DATASETS ---\n",
      " il y a 154 √©chantillons dans le dataset de segmentation.\n",
      " il y a 1274 √©chantillons dans le dataset de classification.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def inspect_dataset_item_robust(dataset, name):\n",
    "    print(f\"\\nüîé INSPECTION : {name}\")\n",
    "    try:\n",
    "        item = dataset[500]\n",
    "        \n",
    "        # Cas 1 : C'est une Liste (Segmentation avec plusieurs patchs)\n",
    "        if isinstance(item, list):\n",
    "            print(f\"   üì¶ C'est une LISTE de {len(item)} patchs.\")\n",
    "            first_patch = item[0]\n",
    "            print(f\"   -> Inspection du premier patch :\")\n",
    "            for key, value in first_patch.items():\n",
    "                print(f\"      - Cl√© '{key}' : {type(value)}\")\n",
    "                if 'numpy' in str(type(value)):\n",
    "                    print(f\" COUPABLE ! (NumPy dans la liste)\")\n",
    "        \n",
    "        # Cas 2 : C'est un Dictionnaire (Classification)\n",
    "        elif isinstance(item, dict):\n",
    "            print(f\"   üì¶ C'est un DICTIONNAIRE unique.\")\n",
    "            for key, value in item.items():\n",
    "                print(f\"      - Cl√© '{key}' : {type(value)}\")\n",
    "                if 'numpy' in str(type(value)):\n",
    "                    print(f\"COUPABLE ! (NumPy dans le dict)\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur d'inspection : {e}\")\n",
    "\n",
    "# Lance l'inspection\n",
    "inspect_dataset_item_robust(train_dataloaders['classification'].dataset, \"Train Segmentation\")\n",
    "\n",
    "#inspection train_datalaoders\n",
    "print(\"\\n--- INSPECTION DES DATASETS ---\")\n",
    "print(f\" il y a {len(train_dataloaders['segmentation'].dataset)} √©chantillons dans le dataset de segmentation.\")\n",
    "print(f\" il y a {len(train_dataloaders['classification'].dataset)} √©chantillons dans le dataset de classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbbb7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Total Params: 14273074\n",
      "Trainable Params: 14273068\n",
      "Non-trainable Params: 6\n",
      "========================================\n",
      "LOG FORMAT | classification_LOSS val_auc_class_0 val_auc_class_1 val_auc_class_2 val_auc_class_3 val_auc_class_4 val_auc_class_5 val_auc_mean | segmentation_LOSS dice_c1 dice_c2 dice_c3 dice_c4 dice_c5 | TIME\n",
      " attributs du trainer : ['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_compute_loss', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_prepare_dataloaders', '_prepare_model', '_prepare_optimizer', '_prepare_tw', '_process_data', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bacth_forward_AutoLambda', 'bacth_forward_FORUM', 'bacth_forward_MOML', 'bfloat16', 'bilevel_methods', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'device', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'forward4loss', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'kwargs', 'load_path', 'load_state_dict', 'meter', 'model', 'modules', 'mtia', 'multi_input', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'optimizer', 'parameters', 'process_preds', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'rep_grad', 'requires_grad_', 'save_path', 'scheduler', 'scheduler_param', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'task_dict', 'task_name', 'task_num', 'test', 'to', 'to_empty', 'train', 'train_bilevel', 'train_singlelevel', 'training', 'type', 'weighting', 'xpu', 'zero_grad']\n",
      " devices du trainer : cuda:0\n",
      " task num : 2\n",
      " task name : ['classification', 'segmentation']\n",
      " weighting : EW\n",
      "multi input : True\n",
      "kwargs : {'arch_args': {}, 'weight_args': {}}\n",
      " meter dict : <LibMTL._record._PerformanceMeter object at 0x7f70cbb0a800>\n",
      "optimiser : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.99\n",
      "    nesterov: True\n",
      "    weight_decay: 3e-05\n",
      ")\n",
      "scheduler : <torch.optim.lr_scheduler.LambdaLR object at 0x7f70cbb0a050>\n",
      "model type : <class 'LibMTL.trainer.Trainer._prepare_model.<locals>.MTLmodel'>\n",
      "--- Arbre g√©n√©alogique (MRO) ---\n",
      "0. MTLmodel\n",
      "1. Unet_hemo\n",
      "2. AbsArchitecture\n",
      "3. EW\n",
      "4. AbsWeighting\n",
      "5. Module\n",
      "6. object\n"
     ]
    }
   ],
   "source": [
    "from LibMTL.trainer import Trainer\n",
    "\n",
    "test_trainer =Trainer(\n",
    "    task_dict=task_dict,\n",
    "    weighting= 'EW',\n",
    "    architecture='Unet_hemo',\n",
    "    #save_path=SAVE_DIR, √† ajouter   \n",
    "    encoder_class=HemorrhageEncoder,\n",
    "    decoders=decoders,\n",
    "    rep_grad=False,\n",
    "    multi_input=True,\n",
    "    optim_param=optim_param,\n",
    "    scheduler_param=scheduler_param,\n",
    "    #device='cuda',\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "print (f\" attributs du trainer : {dir(test_trainer)}\")\n",
    "print (f\" devices du trainer : {test_trainer.device}\")\n",
    "print (f\" task num : {test_trainer.task_num}\")\n",
    "print (f\" task name : {test_trainer.task_name}\")\n",
    "print (f\" weighting : {test_trainer.weighting}\")\n",
    "print(f\"multi input : {test_trainer.multi_input}\")\n",
    "print(f\"kwargs : {test_trainer.kwargs}\")\n",
    "\n",
    "print(f\" meter dict : {test_trainer.meter}\")\n",
    "\n",
    "#prepare optimizer\n",
    "print(f\"optimiser : {test_trainer.optimizer}\")\n",
    "print(f\"scheduler : {test_trainer.scheduler}\")\n",
    "\n",
    "#prepare model \n",
    "print(f\"model type : {type(test_trainer.model)}\")\n",
    "\n",
    "print(\"--- Arbre g√©n√©alogique (MRO) ---\")\n",
    "# MRO = Method Resolution Order\n",
    "for i, parent in enumerate(test_trainer.model.__class__.mro()):\n",
    "    print(f\"{i}. {parent.__name__}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14fc0254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "Layer (type:depth-idx)                                       Output Shape              Param #\n",
      "==============================================================================================================\n",
      "MTLmodel                                                     [2, 6, 96, 96, 96]        --\n",
      "‚îú‚îÄHemorrhageEncoder: 1-1                                     [2, 256, 6, 6, 6]         6\n",
      "‚îÇ    ‚îî‚îÄTwoConv: 2-1                                          [2, 32, 96, 96, 96]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConvolution: 3-1                                 [2, 32, 96, 96, 96]       960\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConvolution: 3-2                                 [2, 32, 96, 96, 96]       27,744\n",
      "‚îÇ    ‚îî‚îÄDown: 2-2                                             [2, 32, 48, 48, 48]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool3d: 3-3                                   [2, 32, 48, 48, 48]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄTwoConv: 3-4                                     [2, 32, 48, 48, 48]       55,488\n",
      "‚îÇ    ‚îî‚îÄDown: 2-3                                             [2, 64, 24, 24, 24]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool3d: 3-5                                   [2, 32, 24, 24, 24]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄTwoConv: 3-6                                     [2, 64, 24, 24, 24]       166,272\n",
      "‚îÇ    ‚îî‚îÄDown: 2-4                                             [2, 128, 12, 12, 12]      --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool3d: 3-7                                   [2, 64, 12, 12, 12]       --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄTwoConv: 3-8                                     [2, 128, 12, 12, 12]      664,320\n",
      "‚îÇ    ‚îî‚îÄDown: 2-5                                             [2, 256, 6, 6, 6]         --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄMaxPool3d: 3-9                                   [2, 128, 6, 6, 6]         --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄTwoConv: 3-10                                    [2, 256, 6, 6, 6]         2,655,744\n",
      "‚îú‚îÄModuleDict: 1-2                                            --                        --\n",
      "‚îÇ    ‚îî‚îÄClassificationDecoder: 2-6                            [2, 6]                    --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-11                                 [2, 6]                    8,523,526\n",
      "‚îÇ    ‚îî‚îÄSegmentationDecoder: 2-7                              [2, 6, 96, 96, 96]        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄUpCat: 3-12                                      [2, 128, 12, 12, 12]      1,590,144\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄUpCat: 3-13                                      [2, 64, 24, 24, 24]       397,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄUpCat: 3-14                                      [2, 32, 48, 48, 48]       99,552\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄUpCat: 3-15                                      [2, 32, 96, 96, 96]       91,360\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄConv3d: 3-16                                     [2, 6, 96, 96, 96]        198\n",
      "==============================================================================================================\n",
      "Total params: 14,273,074\n",
      "Trainable params: 14,273,068\n",
      "Non-trainable params: 6\n",
      "Total mult-adds (G): 271.11\n",
      "==============================================================================================================\n",
      "Input size (MB): 7.08\n",
      "Forward/backward pass size (MB): 4834.22\n",
      "Params size (MB): 57.09\n",
      "Estimated Total Size (MB): 4898.39\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# R√©sum√© du mod√®le avec torchinfo\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    # On simule une entr√©e (batch_size, channels, H, W, D)\n",
    "\n",
    "    print(summary(test_trainer.model, input_size=(2, 1, 96, 96, 96), depth=3))\n",
    "except ImportError:\n",
    "    print(\"Installe torchinfo avec 'pip install torchinfo' pour une belle visualisation\")\n",
    "except Exception as e:\n",
    "    print(f\"Impossible de r√©sumer : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7b80832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Forward Pass Manuel ---\n",
      "Succ√®s ! (Ce serait surprenant)\n",
      "Sortie classification: shape torch.Size([2, 6])\n",
      "Sortie segmentation: shape torch.Size([2, 6, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Cr√©ation d'un faux batch (1 image, 1 canal, 96x96x96)\n",
    "dummy_input = torch.randn(2, 1, 96, 96, 96).to(test_trainer.device)\n",
    "\n",
    "print(\"--- Test Forward Pass Manuel ---\")\n",
    "try:\n",
    "    # On passe l'input dans le mod√®le\n",
    "    outputs = test_trainer.model(dummy_input)\n",
    "    \n",
    "    print(\"Succ√®s ! (Ce serait surprenant)\")\n",
    "    for task, out in outputs.items():\n",
    "        print(f\"Sortie {task}: shape {out.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"\\nBOOM ! Erreur d√©tect√©e :\")\n",
    "    print(e)\n",
    "    \n",
    "    # Inspectons la sortie de l'encodeur seul pour confirmer\n",
    "    print(\"\\n--- Inspection de l'Encodeur seul ---\")\n",
    "    enc_out = test_trainer.model.encoder(dummy_input)\n",
    "    print(f\"Shape sortie encodeur : {enc_out.shape}\")\n",
    "    if len(enc_out.shape) == 2:\n",
    "        print(\"-> CONFIRM√â : L'encodeur renvoie un vecteur plat (Batch, Features).\")\n",
    "        print(\"-> La segmentation a besoin de (Batch, Features, D, H, W).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "992159f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspection de l'Encodeur seul ---\n",
      "Type sortie encodeur : <class 'list'>\n",
      "Nombre d'√©l√©ments : 5\n",
      "enc_out[0].shape : torch.Size([2, 256, 6, 6, 6])\n",
      "enc_out[1].shape : torch.Size([2, 128, 12, 12, 12])\n",
      "enc_out[2].shape : torch.Size([2, 64, 24, 24, 24])\n",
      "enc_out[3].shape : torch.Size([2, 32, 48, 48, 48])\n",
      "enc_out[4].shape : torch.Size([2, 32, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Inspection de l'Encodeur seul ---\")\n",
    "enc_out = test_trainer.model.encoder(dummy_input)\n",
    "print(f\"Type sortie encodeur : {type(enc_out)}\")\n",
    "print(f\"Nombre d'√©l√©ments : {len(enc_out)}\")\n",
    "for i, tensor in enumerate(enc_out):\n",
    "    print(f\"enc_out[{i}].shape : {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baed2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test d√©codeur classification seul ---\n",
      "Bottleneck (enc_out[0]) shape: torch.Size([2, 256, 6, 6, 6])\n",
      "Classification output shape: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Test d√©codeur classification seul ---\")\n",
    "enc_out = test_trainer.model.encoder(dummy_input)\n",
    "print(f\"Bottleneck (enc_out[0]) shape: {enc_out[0].shape}\")\n",
    "\n",
    "try:\n",
    "    cls_output = test_trainer.model.decoders['classification'](enc_out)\n",
    "    print(f\"Classification output shape: {cls_output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur dans le d√©codeur de classification: {e}\")\n",
    "    \n",
    "    print(\"\\n--- Debug √©tape par √©tape ---\")\n",
    "    x4 = enc_out[0]\n",
    "    print(f\"1. Input x4: {x4.shape}\")\n",
    "    \n",
    "    pool = nn.AdaptiveAvgPool3d((4, 4, 4))\n",
    "    after_pool = pool(x4)\n",
    "    print(f\"2. After AdaptiveAvgPool3d: {after_pool.shape}\")\n",
    "    \n",
    "    after_flatten = torch.flatten(after_pool, start_dim=1)\n",
    "    print(f\"3. After Flatten: {after_flatten.shape}\")\n",
    "    print(f\"   Expected: [2, 16384]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "702e8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test du forward complet avec debug ---\n",
      "\n",
      "‚úÖ Succ√®s !\n",
      "Sortie classification: torch.Size([2, 6])\n",
      "Sortie segmentation: torch.Size([2, 6, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Test du forward complet avec debug ---\")\n",
    "\n",
    "# Patch temporaire pour voir ce qui se passe dans _prepare_rep\n",
    "original_prepare_rep = test_trainer.model._prepare_rep\n",
    "\n",
    "def debug_prepare_rep(ss_rep, task, same_rep=None):\n",
    "    print(f\"\\nüîç _prepare_rep appel√© pour task: {task}\")\n",
    "    print(f\"   Type de ss_rep avant: {type(ss_rep)}\")\n",
    "    if isinstance(ss_rep, list):\n",
    "        print(f\"   Liste de {len(ss_rep)} √©l√©ments\")\n",
    "        for i, x in enumerate(ss_rep):\n",
    "            print(f\"     ss_rep[{i}].shape: {x.shape}\")\n",
    "    else:\n",
    "        print(f\"   ss_rep.shape: {ss_rep.shape}\")\n",
    "    \n",
    "    result = original_prepare_rep(ss_rep, task, same_rep)\n",
    "    \n",
    "    print(f\"   Type de ss_rep apr√®s: {type(result)}\")\n",
    "    if isinstance(result, list):\n",
    "        print(f\"   Liste de {len(result)} √©l√©ments\")\n",
    "        for i, x in enumerate(result):\n",
    "            print(f\"     result[{i}].shape: {x.shape}\")\n",
    "    else:\n",
    "        print(f\"   result.shape: {result.shape}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Remplacer temporairement\n",
    "test_trainer.model._prepare_rep = debug_prepare_rep\n",
    "\n",
    "# Tester le forward\n",
    "try:\n",
    "    outputs = test_trainer.model(dummy_input)\n",
    "    print(\"\\n‚úÖ Succ√®s !\")\n",
    "    for task, out in outputs.items():\n",
    "        print(f\"Sortie {task}: {out.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erreur: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4589cfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scanner de l'Encodeur ---\n",
      "Type de sortie : <class 'list'>\n",
      "Nombre d'√©l√©ments dans la liste : 5\n",
      "\n",
      "--- D√©tail des Skip Connections ---\n",
      "Feature 0 shape : torch.Size([2, 256, 6, 6, 6])\n",
      "Feature 1 shape : torch.Size([2, 128, 12, 12, 12])\n",
      "Feature 2 shape : torch.Size([2, 64, 24, 24, 24])\n",
      "Feature 3 shape : torch.Size([2, 32, 48, 48, 48])\n",
      "Feature 4 shape : torch.Size([2, 32, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn(2, 1, 96, 96, 96).to(test_trainer.device)\n",
    "\n",
    "print(\"--- Scanner de l'Encodeur ---\")\n",
    "# On r√©cup√®re la liste\n",
    "enc_out = test_trainer.model.encoder(dummy_input)\n",
    "\n",
    "print(f\"Type de sortie : {type(enc_out)}\")\n",
    "print(f\"Nombre d'√©l√©ments dans la liste : {len(enc_out)}\")\n",
    "\n",
    "print(\"\\n--- D√©tail des Skip Connections ---\")\n",
    "for i, feat in enumerate(enc_out):\n",
    "    print(f\"Feature {i} shape : {feat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5005d",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be35e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mad_92_ywlcod\u001b[0m (\u001b[33mad_92_ywlcod-polytechnique-montr-al\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/examples/My_model/wandb/run-20251127_171216-w16pit7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test/runs/w16pit7f' target=\"_blank\">multitask_unet3d_libMTL</a></strong> to <a href='https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test' target=\"_blank\">https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test/runs/w16pit7f' target=\"_blank\">https://wandb.ai/ad_92_ywlcod-polytechnique-montr-al/hemorrhage_multitask_test/runs/w16pit7f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Total Params: 14273074\n",
      "Trainable Params: 14273068\n",
      "Non-trainable Params: 6\n",
      "========================================\n",
      "LOG FORMAT | classification_LOSS val_auc_class_0 val_auc_class_1 val_auc_class_2 val_auc_class_3 val_auc_class_4 val_auc_class_5 val_auc_mean | segmentation_LOSS dice_c1 dice_c2 dice_c3 dice_c4 dice_c5 | TIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:   6%|‚ñå         | 39/637 [00:20<07:27,  1.34batch/s, loss=1.3899]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  10%|‚ñâ         | 61/637 [00:27<02:33,  3.75batch/s, loss=1.2836]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  14%|‚ñà‚ñé        | 86/637 [00:35<02:05,  4.38batch/s, loss=1.1967]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  15%|‚ñà‚ñç        | 95/637 [00:37<02:00,  4.51batch/s, loss=1.3059]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  24%|‚ñà‚ñà‚ñç       | 154/637 [00:53<02:11,  3.67batch/s, loss=2.0487]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 286/637 [01:27<01:50,  3.17batch/s, loss=1.7392]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 309/637 [01:33<02:12,  2.48batch/s, loss=1.8434]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 355/637 [01:44<01:05,  4.32batch/s, loss=1.5317]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 388/637 [01:53<01:28,  2.82batch/s, loss=1.1523]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 412/637 [02:00<01:31,  2.47batch/s, loss=1.6664]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 550/637 [02:37<00:31,  2.74batch/s, loss=1.5227]/home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2420329, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n",
      "                                                                               /home/tibia/miniconda3/envs/libmtl/lib/python3.10/site-packages/monai/transforms/utils.py:679: UserWarning: Num foregrounds 0, Num backgrounds 2745080, unable to generate class balanced samples, setting `pos_ratio` to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 | TRAIN: 0.4220 0.4589 0.4322 0.4955 0.4901 0.4910 0.4728 0.4734 | 1.1279 0.0007 0.2995 0.0000 0.0001 0.0004 0.0601 | Time: 184.6781 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (6,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m\n\u001b[1;32m     39\u001b[0m hemorrhage_trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     40\u001b[0m     task_dict\u001b[38;5;241m=\u001b[39mtask_dict,\n\u001b[1;32m     41\u001b[0m     weighting\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEW\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#  Entra√Ænement\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mhemorrhage_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/trainer.py:255\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_dataloaders, test_dataloaders, epochs, val_dataloaders, return_weight, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     train_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_singlelevel\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/trainer.py:361\u001b[0m, in \u001b[0;36mTrainer.train_singlelevel\u001b[0;34m(self, train_dataloaders, test_dataloaders, epochs, val_dataloaders, return_weight)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_dataloaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mhas_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     val_improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_improvement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m##-------------Ajout perso -------------\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     total_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/trainer.py:442\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, test_dataloaders, epoch, mode, return_improvement)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mrecord_time(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mget_score()\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mimprovement\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mreinit()\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/_record.py:72\u001b[0m, in \u001b[0;36m_PerformanceMeter.display\u001b[0;34m(self, mode, epoch)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_best_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults, epoch)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_val \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_best_result_by_val\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     p_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/_record.py:95\u001b[0m, in \u001b[0;36m_PerformanceMeter._update_best_result_by_val\u001b[0;34m(self, new_result, epoch, mode)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_best_result_by_val\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_result, epoch, mode):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m         improvement \u001b[38;5;241m=\u001b[39m \u001b[43mcount_improvement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimprovement \u001b[38;5;241m=\u001b[39m improvement\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m improvement \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimprovement\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/store/home/tibia/Projet_Hemorragie/LibMTL/LibMTL/LibMTL/utils.py:74\u001b[0m, in \u001b[0;36mcount_improvement\u001b[0;34m(base_result, new_result, weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(base_result\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m---> 74\u001b[0m     improvement \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_result\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_result\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m     76\u001b[0m                      np\u001b[38;5;241m.\u001b[39marray(base_result[task]))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     77\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m improvement\u001b[38;5;241m/\u001b[39mcount\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,) (6,) "
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "config_l = dict(\n",
    "    sharing_type=\"hard\",   # \"soft\" ou \"fine_tune\"\n",
    "    model=\"BasicUNetWithClassification\",\n",
    "    loss_weighting=\"none\",\n",
    "    dataset_size=\"balanced\",  # \"full\" ou \"balanced\" ou \"optimized\"\n",
    "    batch_size=2,\n",
    "    learning_rate=1e-3,\n",
    "    optimizer=\"sgd\",\n",
    "    batch_strat√©gie= \"loop\", \n",
    "    seed=42\n",
    ")\n",
    "torch.cuda.set_device(0)\n",
    "# G√©n√©ration automatique de tags √† partir de config\n",
    "tags = [f\"{k}:{v}\" for k, v in config_l.items() if k in [\"sharing_type\", \"optimizer\", \"model\", \"loss_weighting\"]]\n",
    "\n",
    "\n",
    "# : Initialisation manuelle de wandb\n",
    "# Au lieu de : wandb_logger = WandbLogger(...)\n",
    "wandb.init(\n",
    "    project=\"hemorrhage_multitask_test\",\n",
    "    group=\"noponderation\",\n",
    "    tags=tags,\n",
    "    config=config_l,\n",
    "    name=\"multitask_unet3d_libMTL\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3Ô∏è M√©thodes multit√¢ches\n",
    "from LibMTL.architecture import HPS\n",
    "from LibMTL.weighting import GradNorm\n",
    "\n",
    "# 4Ô∏è Instanciation du Trainer\n",
    "from LibMTL.trainer import Trainer\n",
    "\n",
    "hemorrhage_trainer = Trainer(\n",
    "    task_dict=task_dict,\n",
    "    weighting= 'EW',\n",
    "    architecture='Unet_hemo',\n",
    "    #save_path=SAVE_DIR, √† ajouter \n",
    "    encoder_class=HemorrhageEncoder,\n",
    "    decoders=decoders,\n",
    "    rep_grad=False,\n",
    "    multi_input=True,\n",
    "    optim_param=optim_param,\n",
    "    scheduler_param=scheduler_param,\n",
    "    #device='cuda',\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "#  Entra√Ænement\n",
    "hemorrhage_trainer.train(train_dataloaders, test_dataloaders = None, epochs=1000 , val_dataloaders=val_dataloaders)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libmtl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
